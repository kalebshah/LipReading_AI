{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1g2EXEC5H7Q"
   },
   "source": [
    "## Install Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2856,
     "status": "ok",
     "timestamp": 1715891210687,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "-EogM2V95C8_",
    "outputId": "ac3f68bc-4bd4-4b1a-c449-9705ceaa117a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import cv2  # OpenCV library for video processing\n",
    "import torch  # PyTorch library for deep learning\n",
    "import os  # For file and directory manipulation\n",
    "import numpy as np  # Numerical computing library\n",
    "from typing import List  # Type hinting for clarity\n",
    "from matplotlib import pyplot as plt  # For visualization\n",
    "import imageio  # For creating GIFs\n",
    "import gdown  # For downloading data from Google Drive\n",
    "from torch.utils.data import Dataset, DataLoader  # For creating data loaders\n",
    "import torch.nn as nn  # Neural network modules\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "from torchvision import datasets, transforms  # Image and video transformations\n",
    "import torch.nn.functional as F  # Functional interface for neural network operations\n",
    "from torch.nn.utils.rnn import pad_sequence  # Padding for sequencesF\n",
    "\n",
    "# Set device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Connecting Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7003,
     "status": "ok",
     "timestamp": 1715891217687,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "Gxi5fYSL5UIf",
    "outputId": "4fc32454-4ee2-4c65-e450-ce7995bd8a86"
   },
   "outputs": [],
   "source": [
    "# # Extracting Files From Previously Downloaded Data (needed for google colab)\n",
    "# url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "# output = 'data.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('data.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Wm93ilw5o1O"
   },
   "source": [
    "# Data Loading and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1715891217688,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "lBh6gXVH5P9h"
   },
   "outputs": [],
   "source": [
    "# Helper class for character mapping including encoding and decoding character strings\n",
    "class CharMap:\n",
    "    def __init__(self):\n",
    "        self.vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"] + [\"<pad>\"]\n",
    "        self.char_to_num = {char: num for num, char in enumerate(self.vocab)}\n",
    "        self.num_to_char = {num: char for char, num in self.char_to_num.items()}\n",
    "        self.pad_token_idx = self.char_to_num[\"<pad>\"]  # Store the index of the <pad> token\n",
    "\n",
    "    def encode(self, text):\n",
    "        return [self.char_to_num[char] for char in text if char in self.char_to_num]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        # Decode, ignoring indices corresponding to <pad>\n",
    "        return ''.join(self.num_to_char[idx] for idx in indices if idx != self.pad_token_idx)\n",
    "\n",
    "char_map = CharMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1715891217688,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "7nj0_0ep5P5J"
   },
   "outputs": [],
   "source": [
    "# Function to load and preprocess video frames\n",
    "def load_video(path: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loads a video file, preprocesses the frames, and returns a PyTorch tensor of normalized frames.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(path)  # Open the video file\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):  # Iterate over frames\n",
    "        ret, frame = cap.read()  # Read a frame\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        frames.append(frame[190:236, 80:220])  # Crop region of interest\n",
    "    cap.release()  # Release the video capture object\n",
    "\n",
    "    frames = torch.tensor(frames, dtype=torch.float32)  # Convert frames to PyTorch tensor\n",
    "    mean = frames.mean()  # Calculate mean\n",
    "    std = frames.std()  # Calculate standard deviation\n",
    "    return (frames - mean) / std  # Normalize pixel values\n",
    "\n",
    "# Function to load and process alignment files\n",
    "def load_alignments(path: str) -> torch.Tensor:  # Changed return type to torch.Tensor\n",
    "    \"\"\"\n",
    "    Loads alignments from a file and converts them to a PyTorch tensor of character indices.\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()  # Read all lines from the alignment file\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()  # Split the line into words\n",
    "        if line[2] != 'sil':  # Check if the word is not silence ('sil')\n",
    "            tokens.extend([' ', line[2]])  # Add a space and the word to the tokens list\n",
    "    tokens = [char for token in tokens for char in token]  # Flatten the list of tokens\n",
    "    indices = [char_map.char_to_num[char] for char in tokens[1:]]  # Convert characters to numerical indices\n",
    "    return torch.tensor(indices, dtype=torch.long)  # Return a PyTorch tensor of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1715891217688,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "ZusymqVC5PuM"
   },
   "outputs": [],
   "source": [
    "# Function to load both video and alignment data\n",
    "def load_data(path: str):\n",
    "    \"\"\"\n",
    "    Loads video frames and alignments from the specified path.\n",
    "    \"\"\"\n",
    "    file_name = os.path.splitext(os.path.basename(path))[0]  # Extract filename without extension\n",
    "    video_path = os.path.join('data', 's1', f'{file_name}.mpg')  # Construct video path\n",
    "    alignment_path = os.path.join('data', 'alignments', 's1', f'{file_name}.align')  # Construct alignment path\n",
    "\n",
    "    if os.path.exists(alignment_path):  # Check if alignment file exists\n",
    "        frames = load_video(video_path)  # Load video frames\n",
    "        alignments = load_alignments(alignment_path)  # Load alignments\n",
    "        return frames, alignments\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Testing if Data was loaded as expected and the tensors are correct size.\n",
    "# test_path = \"/content/data/s1/bbaf3s.mpg\"\n",
    "# frames, alignments = load_data(test_path)\n",
    "# plt.imshow(frames[35].cpu().numpy(), cmap='gray')\n",
    "# plt.show()\n",
    "# print(alignments.size())\n",
    "# print(frames.size())\n",
    "# print(''.join([char_map.num_to_char[num.item()] for num in alignments]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1715891217688,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "gs96SQjF5zS_"
   },
   "outputs": [],
   "source": [
    "# Dataset class for lip reading data\n",
    "class LipReadingDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths  # Store list of file paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)  # Return the number of data samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.file_paths[index]  # Get file path for the given index\n",
    "        data = load_data(path)  # Load data (frames and alignments)\n",
    "        if data is not None:\n",
    "            frames, alignments = data\n",
    "            return frames, alignments\n",
    "        else:\n",
    "            return self.__getitem__(index + 1)  # If data is None, try the next index\n",
    "\n",
    "        return video, alignment\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Collate function to add padding to both frames and alignments tensors\n",
    "def collate_fn(batch):\n",
    "    videos, alignments = zip(*batch)\n",
    "    # Convert list of arrays or tensors to padded tensor\n",
    "    # Use .clone().detach() to safely create a new tensor detached from the computation graph\n",
    "    padded_videos = pad_sequence([v.clone().detach() if isinstance(v, torch.Tensor) else torch.tensor(v) for v in videos], batch_first=True)\n",
    "    padded_alignments = pad_sequence([a.clone().detach() if isinstance(a, torch.Tensor) else torch.tensor(a) for a in alignments], batch_first=True, padding_value=char_map.char_to_num[\"<pad>\"])\n",
    "    return padded_videos, padded_alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1510,
     "status": "ok",
     "timestamp": 1715891219180,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "F8XHZhIjBY-C"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from textblob import TextBlob\n",
    "\n",
    "## Create Function to convert predictions from Model into character strings without padding\n",
    "def decode_predictions(output, char_map):\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    probabilities = F.softmax(output, dim=2)\n",
    "    # Use argmax to get the most likely character indices\n",
    "    max_indices = torch.argmax(probabilities, dim=2)\n",
    "    batch_size = max_indices.size(0)\n",
    "    pad_token_idx = char_map.char_to_num[\"<pad>\"]  # Get the index for the pad token\n",
    "\n",
    "    # Decode each sequence in the batch, ignoring pad characters\n",
    "    decoded_batch = []\n",
    "    for i in range(batch_size):\n",
    "        decoded_text = ''.join([char_map.num_to_char[idx.item()] for idx in max_indices[i] if idx.item() != pad_token_idx])\n",
    "        decoded_batch.append(decoded_text)\n",
    "\n",
    "    return decoded_batch\n",
    "\n",
    "def clean_and_correct_text(text):\n",
    "    # Correct spelling using TextBlob\n",
    "    blob = TextBlob(text)\n",
    "    corrected_text = str(blob.correct())\n",
    "\n",
    "    # Tokenize the corrected text and normalize whitespace\n",
    "    tokens = corrected_text.split()\n",
    "\n",
    "    # Concatenate tokens until the 30 character limit is reached\n",
    "    result_text = \"\"\n",
    "    for token in tokens:\n",
    "        if len(result_text) + len(token) + 1 > 31:  # +1 for the space\n",
    "            break\n",
    "        result_text += (token + \" \")\n",
    "\n",
    "    return result_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I48WpZqY58IZ"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 1547,
     "status": "ok",
     "timestamp": 1715891220724,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "2H6Pnt8C5y_R",
    "outputId": "b64ec5a8-3763-43d9-b5d5-89427f313ec5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-a0f209aa9a03>:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  frames = torch.tensor(frames, dtype=torch.float32)  # Convert frames to PyTorch tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames shape: torch.Size([2, 75, 46, 140])\n",
      "Alignments shape: torch.Size([2, 24])\n",
      "[11, 0, 24, 38, 6, 17, 4, 4, 13, 38, 0, 19, 38, 11, 38, 4, 8, 6, 7, 19, 38, 13, 14, 22]\n",
      "lay green at l eight now\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ba5e621c040>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Read all file names from the Data directory\n",
    "data_dir = 'data/s1/'\n",
    "file_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.mpg')]\n",
    "dataset = LipReadingDataset(file_paths)\n",
    "\n",
    "# ## Create Train Test Split\n",
    "# train_size = int(0.9 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "## Decides the number of channels in each tensor\n",
    "batch_size = 2  # Setting the batch size\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# Test if padding worked as expected and all tensors are of uniform size\n",
    "batch = next(iter(test_loader))\n",
    "frames, alignments = batch\n",
    "print(f\"Frames shape: {frames.shape}\")\n",
    "print(f\"Alignments shape: {alignments.shape}\")\n",
    "\n",
    "# Visualize the first frame of the first video in the batch\n",
    "# Print the alignments for the sample video\n",
    "sample_alignments = alignments[0].tolist()\n",
    "print(sample_alignments)\n",
    "print(char_map.decode(sample_alignments))\n",
    "plt.imshow(frames[0][74].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1715891220724,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "wFmbvbwA_wI3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import csv\n",
    "\n",
    "class LipNetModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LipNetModel, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 128, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool3d((1, 2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool3d((1, 2, 2))\n",
    "\n",
    "        self.conv3 = nn.Conv3d(256, 75, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool3d((1, 2, 2))\n",
    "\n",
    "        # Adjust the GRU layers to not use dropout internally since they have only one layer\n",
    "        self.gru1 = nn.GRU(6375, 128, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)  # Add dropout layer manually after the first GRU\n",
    "        self.gru2 = nn.GRU(256, 128, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)  # Add dropout layer manually after the second GRU\n",
    "\n",
    "        self.fc = nn.Linear(256, num_classes)  # Output layer to number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Flatten the features into [batch, seq_len, feature]\n",
    "        x = x.view(x.size(0), x.size(2), -1)\n",
    "\n",
    "        x, _ = self.gru1(x)\n",
    "        x = self.dropout1(x)  # Apply dropout after the first GRU\n",
    "        x, _ = self.gru2(x)\n",
    "        x = self.dropout2(x)  # Apply dropout after the second GRU\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVwiRzUE9qGI"
   },
   "source": [
    "# Testing loop (over entire dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1715891297724,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "TOkNKHkX9pa1",
    "outputId": "dc62ec90-d1e3-4408-d2aa-7586f23496ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on GPU\n"
     ]
    }
   ],
   "source": [
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create instance of the model\n",
    "model = LipNetModel(num_classes=len(char_map.vocab)).to(device)\n",
    "\n",
    "# Loading from google drive since using google colab\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Load the model state dict on the GPU\n",
    "    model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/model_1_checkpoints/2_lip_reading_model_100.pth', map_location=torch.device('cuda')))\n",
    "    print(\"Model loaded on GPU\")\n",
    "else:\n",
    "    # If CUDA is not available, load on CPU instead\n",
    "    model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/model_1_checkpoints/2_lip_reading_model_100.pth', map_location=torch.device('cpu')))\n",
    "    print(\"CUDA is not available. Model loaded on CPU\")\n",
    "\n",
    "# ## Loading from repository directly\n",
    "# model.load_state_dict(torch.load('/Model_Checkpoints/lip_nn_model_post_100_epoch.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8918,
     "status": "ok",
     "timestamp": 1715891244381,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "gLoYXbPgAtsh",
    "outputId": "49aa4b13-4e3d-43a5-8bcc-282cc34d32f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
      "Collecting Levenshtein==0.25.1 (from python-Levenshtein)\n",
      "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python-Levenshtein)\n",
      "  Downloading rapidfuzz-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.25.1 python-Levenshtein-0.25.1 rapidfuzz-3.9.0\n"
     ]
    }
   ],
   "source": [
    "# pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 359981,
     "status": "error",
     "timestamp": 1715891668157,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "2n4hkcIl6brn",
    "outputId": "332459cc-dd4c-45b8-e3ba-d44bbc7fe8ac"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import Levenshtein as lv  # Levenshtein package for edit distance calculation\n",
    "import csv\n",
    "\n",
    "def test_model(test_loader, model, char_map):\n",
    "    model.eval()\n",
    "    test_results = []\n",
    "    iteration_number = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.unsqueeze(1).to(device)  # Ensure input dimensions and device are correct\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Decode outputs to text without padding\n",
    "            decoded_texts = decode_predictions(outputs, char_map)\n",
    "            # Post-process decoded texts\n",
    "            post_processed_texts = [clean_and_correct_text(text) for text in decoded_texts]\n",
    "\n",
    "            # Retrieve original texts from labels\n",
    "            original_texts = [char_map.decode(label.tolist()) for label in labels]\n",
    "\n",
    "            # Calculate metrics and print results\n",
    "            for original, decoded, post_processed in zip(original_texts, decoded_texts, post_processed_texts):\n",
    "                raw_edit_distance = lv.distance(original, decoded)\n",
    "                post_processed_edit_distance = lv.distance(original, post_processed)\n",
    "                test_results.append({\n",
    "                    'iteration': iteration_number,\n",
    "                    'original_text': original,\n",
    "                    'raw_prediction': decoded,\n",
    "                    'post_processed_prediction': post_processed,\n",
    "                    'raw_edit_distance': raw_edit_distance,\n",
    "                    'post_processed_edit_distance': post_processed_edit_distance\n",
    "                })\n",
    "\n",
    "                # Print the iteration details\n",
    "                print(f\"Iteration {iteration_number}:\")\n",
    "                print(f\"Original Text: {original}\")\n",
    "                print(f\"Post-Processed Prediction: {post_processed}\")\n",
    "                print(f\"Post-Processed Edit Distance: {post_processed_edit_distance}\")\n",
    "                print(\"-\" * 50)  # Separator for clarity\n",
    "\n",
    "                iteration_number += 1\n",
    "\n",
    "                # Save results to CSV every 100 iterations\n",
    "                if iteration_number % 100 == 0:\n",
    "                    with open(f'LipReading_nn_{iteration_number}_predictions.csv', 'w', newline='') as file:\n",
    "                        writer = csv.DictWriter(file, fieldnames=test_results[0].keys())\n",
    "                        writer.writeheader()\n",
    "                        writer.writerows(test_results)\n",
    "\n",
    "    # Ensure remaining results are written to file\n",
    "    if test_results:\n",
    "        with open(f'LipReading_nn_{iteration_number}_predictions.csv', 'w', newline='') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=test_results[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(test_results)\n",
    "\n",
    "    return None  # Depending on use, might not need to return anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1715891947844,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "iicsMXEtAr0s",
    "outputId": "caf561fa-edbb-4db6-8811-7c6de0cc9fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Raw Edit Distance: 16.106\n",
      "Average Post-Processed Edit Distance: 4.887\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# Function toload edit distances from CSV or test results\n",
    "def load_test_results_from_csv(file_path):\n",
    "    # Initialize an empty list to store the test results\n",
    "    test_results = []\n",
    "\n",
    "    # Open the CSV file and read data into the list of dictionaries\n",
    "    with open(file_path, mode='r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            # Convert numeric fields from string to appropriate types\n",
    "            row['raw_edit_distance'] = int(row['raw_edit_distance'])\n",
    "            row['post_processed_edit_distance'] = int(row['post_processed_edit_distance'])\n",
    "            test_results.append(row)\n",
    "\n",
    "    return test_results\n",
    "\n",
    "# Function to compute average edit distance and other metrics\n",
    "def compute_metrics(test_results):\n",
    "    total_raw_edit_distance = sum(result['raw_edit_distance'] for result in test_results)\n",
    "    total_post_processed_edit_distance = sum(result['post_processed_edit_distance'] for result in test_results)\n",
    "    num_samples = len(test_results)\n",
    "    average_raw_edit_distance = total_raw_edit_distance / num_samples\n",
    "    average_post_processed_edit_distance = total_post_processed_edit_distance / num_samples\n",
    "\n",
    "    print(\"Average Raw Edit Distance:\", average_raw_edit_distance)\n",
    "    print(\"Average Post-Processed Edit Distance:\", average_post_processed_edit_distance)\n",
    "\n",
    "# Load test results from CSV\n",
    "file_path = 'LipReading_nn_1000_predictions.csv'\n",
    "test_results = load_test_results_from_csv(file_path)\n",
    "\n",
    "# Compute metrics with the loaded test results\n",
    "compute_metrics(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1223,
     "status": "ok",
     "timestamp": 1715892529107,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "cGJKfzf8Kgtp",
    "outputId": "6a852874-b386-4dad-feec-f4ef97d68eb3"
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# def load_data_from_csv(file_path):\n",
    "#     with open(file_path, mode='r', newline='') as file:\n",
    "#         reader = csv.DictReader(file)\n",
    "#         return list(reader)\n",
    "\n",
    "# def calculate_word_accuracy(test_results):\n",
    "#     word_accuracies = []\n",
    "\n",
    "#     for result in test_results:\n",
    "#         original_words = set(result['original_text'].split())\n",
    "#         predicted_words = set(result['post_processed_prediction'].split())\n",
    "\n",
    "#         # Calculate the number of common words\n",
    "#         common_words = original_words.intersection(predicted_words)\n",
    "#         num_common_words = len(common_words)\n",
    "#         total_words_in_original = len(original_words)\n",
    "\n",
    "#         # Avoid division by zero\n",
    "#         if total_words_in_original > 0:\n",
    "#             accuracy = num_common_words / total_words_in_original\n",
    "#         else:\n",
    "#             accuracy = 0.0  # Can consider it as perfect match if no words to predict\n",
    "\n",
    "#         word_accuracies.append({\n",
    "#             'original_text': result['original_text'],\n",
    "#             'predicted_text': result['post_processed_prediction'],\n",
    "#             'common_word_count': num_common_words,\n",
    "#             'total_original_words': total_words_in_original,\n",
    "#             'word_accuracy': accuracy\n",
    "#         })\n",
    "\n",
    "#         # Optionally print each comparison's details\n",
    "#         print(f\"Original: {result['original_text']}\")\n",
    "#         print(f\"Predicted: {result['post_processed_prediction']}\")\n",
    "#         print(f\"Word Accuracy: {accuracy:.2f}\")\n",
    "#         print('-' * 50)\n",
    "\n",
    "#     return word_accuracies\n",
    "\n",
    "# # Path to your CSV file\n",
    "# file_path = 'LipReading_nn_1000_predictions.csv'\n",
    "# test_results = load_data_from_csv(file_path)\n",
    "# word_accuracies = calculate_word_accuracy(test_results)\n",
    "\n",
    "# # If you need to see the average accuracy\n",
    "# average_accuracy = sum(item['word_accuracy'] for item in word_accuracies) / len(word_accuracies)\n",
    "# print(f\"Average Word Accuracy: {average_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1715892743512,
     "user": {
      "displayName": "Kaleb Shah",
      "userId": "05986787073364614490"
     },
     "user_tz": 300
    },
    "id": "yRWcTNmrKiBh",
    "outputId": "a1695044-db06-48c9-cdd9-86f093b4e614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV with word coverage has been written to: LipReading_nn_1000_predictions_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def load_and_modify_csv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, mode='r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "    return data\n",
    "\n",
    "def calculate_and_add_word_coverage(data):\n",
    "    for row in data:\n",
    "        original_words = set(row['original_text'].split())\n",
    "        predicted_words = set(row['post_processed_prediction'].split())\n",
    "\n",
    "        # Calculate the number of common words\n",
    "        common_words = original_words.intersection(predicted_words)\n",
    "        num_common_words = len(common_words)\n",
    "        total_words_in_original = len(original_words)\n",
    "\n",
    "        # Calculate word accuracy\n",
    "        if total_words_in_original > 0:\n",
    "            word_coverage = num_common_words / total_words_in_original\n",
    "        else:\n",
    "            word_coverage = 0.0  # Can consider it as perfect match if no words to predict\n",
    "\n",
    "        # Add the word accuracy to the row\n",
    "        row['word_coverage'] = word_coverage\n",
    "\n",
    "    return data\n",
    "\n",
    "def write_data_to_csv(data, output_file_path):\n",
    "    if data:\n",
    "        fieldnames = data[0].keys()  # Extract fieldnames from the first row dictionary\n",
    "        with open(output_file_path, 'w', newline='') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "\n",
    "# Path to your CSV file and output file path\n",
    "input_file_path = 'LipReading_nn_1000_predictions.csv'\n",
    "output_file_path = 'LipReading_nn_1000_predictions_updated.csv'\n",
    "\n",
    "# Load data, calculate word coverage, and write to a new CSV\n",
    "data = load_and_modify_csv(input_file_path)\n",
    "data_with_coverage = calculate_and_add_word_coverage(data)\n",
    "write_data_to_csv(data_with_coverage, output_file_path)\n",
    "\n",
    "print(\"Updated CSV with word coverage has been written to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crxancDkLWjF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOJNoKAQiEIZq+axiuQoDD5",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
